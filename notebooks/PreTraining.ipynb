{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ethaniconic/Swalambh_mvp/blob/Dev/PreTraining.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Code by Devashish"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y2mJJcpF4Scc"
      },
      "source": [
        "Kaggle API key"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mMi9H2MoubLO"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "files.upload() # Select your kaggle.json file here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cPNBmHDB4am3"
      },
      "source": [
        "DataSet download (HAM10000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9uyrxCxk4Z4P"
      },
      "outputs": [],
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "\n",
        "# Download dataset (approx 2.6GB)\n",
        "!kaggle datasets download -d kmader/skin-cancer-mnist-ham10000\n",
        "\n",
        "# Unzip quietly (-q) to avoid millions of print lines\n",
        "!unzip -q skin-cancer-mnist-ham10000.zip -d ham10000_data\n",
        "print(\"âœ… Data downloaded and unzipped!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r73wez6d5XkE"
      },
      "source": [
        "Google Drive linking"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yTt6-MwY5egr"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Create a folder for your models if it doesn't exist\n",
        "!mkdir -p /content/drive/MyDrive/DermSight_Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WnRd9Bs15fpf"
      },
      "source": [
        "Model training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5VIgwQuC5-Jy"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import models, transforms\n",
        "from PIL import Image\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.cuda.amp import autocast, GradScaler\n",
        "from tqdm import tqdm # Progress bar\n",
        "\n",
        "# --- CONFIGURATION ---\n",
        "BATCH_SIZE = 64 # T4 GPU can handle this easily\n",
        "EPOCHS = 10     # Train a bit longer since Colab is fast\n",
        "LR = 0.001\n",
        "IMG_SIZE = 224\n",
        "DATA_DIR = './ham10000_data/HAM10000_images_part_1' # Both parts usually merge, but check paths\n",
        "# Note: The Kaggle dataset structure varies sometimes.\n",
        "# We will combine part 1 and part 2 folders essentially by looking in both or moving them.\n",
        "\n",
        "# --- PATH CORRECTION ---\n",
        "# The KMader dataset unzips into multiple folders. Let's find where the images are.\n",
        "image_paths = {}\n",
        "for folder in ['./ham10000_data/HAM10000_images_part_1', './ham10000_data/HAM10000_images_part_2']:\n",
        "    if os.path.exists(folder):\n",
        "        for img in os.listdir(folder):\n",
        "            image_paths[os.path.splitext(img)[0]] = os.path.join(folder, img)\n",
        "\n",
        "print(f\"Found {len(image_paths)} images.\")\n",
        "\n",
        "CSV_FILE = './ham10000_data/HAM10000_metadata.csv'\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# --- 1. DATASET CLASS ---\n",
        "class HAMDataset(Dataset):\n",
        "    def __init__(self, df, img_paths, transform=None):\n",
        "        self.df = df\n",
        "        self.img_paths = img_paths\n",
        "        self.transform = transform\n",
        "        self.class_map = {\n",
        "            'nv': 0, 'mel': 1, 'bkl': 2, 'bcc': 3,\n",
        "            'akiec': 4, 'vasc': 5, 'df': 6\n",
        "        }\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.df.iloc[idx]\n",
        "        img_id = row['image_id']\n",
        "\n",
        "        # Get path from our dictionary\n",
        "        img_path = self.img_paths.get(img_id)\n",
        "\n",
        "        if img_path is None:\n",
        "            # Skip missing images (rare but happens)\n",
        "            return self.__getitem__((idx + 1) % len(self.df))\n",
        "\n",
        "        image = Image.open(img_path).convert('RGB')\n",
        "        label = self.class_map[row['dx']]\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, label\n",
        "\n",
        "# --- 2. PREPARATION ---\n",
        "# Augmentation\n",
        "train_transforms = transforms.Compose([\n",
        "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomVerticalFlip(),\n",
        "    transforms.RandomRotation(20),\n",
        "    transforms.ColorJitter(brightness=0.1, contrast=0.1),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "val_transforms = transforms.Compose([\n",
        "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Load Data\n",
        "full_df = pd.read_csv(CSV_FILE)\n",
        "train_df, val_df = train_test_split(full_df, test_size=0.1, stratify=full_df['dx'])\n",
        "\n",
        "train_dataset = HAMDataset(train_df, image_paths, transform=train_transforms)\n",
        "val_dataset = HAMDataset(val_df, image_paths, transform=val_transforms)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2, pin_memory=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2, pin_memory=True)\n",
        "\n",
        "# --- 3. MODEL (EfficientNet-B0) ---\n",
        "model = models.efficientnet_b0(weights='DEFAULT')\n",
        "num_ftrs = model.classifier[1].in_features\n",
        "model.classifier[1] = nn.Linear(num_ftrs, 7) # 7 Classes\n",
        "model = model.to(DEVICE)\n",
        "\n",
        "# Class Weights for Imbalance\n",
        "class_counts = train_df['dx'].value_counts().sort_index()\n",
        "ordered_counts = [class_counts[k] for k in ['nv','mel','bkl','bcc','akiec','vasc','df']]\n",
        "weights = [1.0 / c for c in ordered_counts]\n",
        "class_weights = torch.FloatTensor(weights).to(DEVICE)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
        "optimizer = optim.Adam(model.parameters(), lr=LR)\n",
        "scaler = GradScaler()\n",
        "\n",
        "# --- 4. TRAINING LOOP ---\n",
        "print(f\"ðŸš€ Starting training on {DEVICE} for {EPOCHS} epochs...\")\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    loop = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{EPOCHS}\")\n",
        "\n",
        "    for images, labels in loop:\n",
        "        images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        with autocast():\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        loop.set_postfix(loss=loss.item())\n",
        "\n",
        "    # Validation\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in val_loader:\n",
        "            images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            val_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    print(f\"Epoch {epoch+1} -> Train Loss: {running_loss/len(train_loader):.4f} | Val Loss: {val_loss/len(val_loader):.4f} | Val Acc: {100 * correct / total:.2f}%\")\n",
        "\n",
        "# --- 5. SAVE MODEL TO DRIVE ---\n",
        "save_path = '/content/drive/MyDrive/DermSight_Models/ham10000_pretrained.pth'\n",
        "torch.save(model.state_dict(), save_path)\n",
        "print(f\"âœ… Model saved successfully to: {save_path}\")\n",
        "print(\"You can now download this file and use it in your local Fusion project!\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "authorship_tag": "ABX9TyM1B0qtfIhCkG9M0z3lOkks",
      "gpuType": "T4",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
